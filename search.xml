<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F12%2F11%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[R-CNN]]></title>
    <url>%2F2017%2F12%2F08%2Frcnn%2F</url>
    <content type="text"><![CDATA[R-CNNR-CNN是将CNN引入物体检测(Object-Detection)的开山之作，一作Ross Girshick也是CV特别是Object-Detection领域的大牛，之后的许多物体检测的工作都有他的身影。 R-CNN这种region proposals+CNN的two-stage框架是后来许多工作SPP-Net, Fast-RCNN, Faster-RCNN的基础。因此读懂R-CNN的架构和流程对读懂之后的文章也至关重要。我希望读者可以从这篇文章中理解以下几点： R-CNN的整个流程是什么样的，这是object-detection工作的核心 R-CNN的优点和缺点在哪里，了解了这个也就知道后面提出改进的论文的motivation 背景知识在开始阅读论文之前，介绍一些必要的背景知识，如果您对这些内容已经非常熟悉了，feel free to skip。 物体检测我们都知道分类任务的目标很简单，给定一张图片，网络输出预测的类别和真实的标记比较，最后用正确率来评测结果。 那么物体检测任务是在干什么呢？简单来说 物体检测不仅需要预测物体的类别，还需要定位出物体的位置，也就是要预测出bounding box表示每一个物体的位置。 另外，图片分类任务每一张图片只需要预测出一种类别，而物体检测对于一张图片需要预测出所有物体（可能有多个类别）。 借用CS231n的课件来直观的感受一下物体检测任务 可以看到，对于第三张图片的3个物体的每一个我们都要给出一个预测框bounding box来预测出物体的位置，并给出物体的类别。 那么给定一个物体检测系统，我们如何去评价它的好坏呢？ 首先我们要知道如何去评价一个bounding box的好坏，这里就有一个很重要的指标叫做IOU。 IOU定义了另个bounding box的重叠程度，如下图所示： A和B分别代表预测的bounding box和ground truth，两个矩形框A和B的重叠程度计算公式就为 $$IOU = \frac{A \cap B}{A \cup B}$$ 好的检测框，应该和标注框有非常大的重叠率，同时又不能对同一个物体重复检测。我们把那些和标注框重叠率很高的定义为true positive(TP)，把那些重叠率低和重复检测的框定义为false positive(FP)。 我们还需要定义两个描述指标：precision 和recall。Precision是true positive 数量除以 true positive和false positive的比值，即所有的检测结果中，正确的比例。 Recall 则是所有truepositive的个数和标注框个数的比值，即所有的目标中，被系统检测出来的比例。 接下来，我们可以把检测的结果根据置信度进行排序， 设一个阈值，然后去计算这个情况下的precision和recall。我们设置不同的阈值，可以得到很多组precision 和recall。 如果我们把所有的precision 和recall 都画到一张图上，x轴代表recall, y轴代表precision,那么我们得到的图，就叫做PR(precision-recall) 曲线。我们可以用这条曲线在x轴上的积分，去描述物体检测的好坏，这个指标叫做Average precision(AP)。 AP值高，就说明系统在比较高recall的情况下，还能保持比较高的的precision。 非极大值抑制以下图为例，在物体检测任务中，我们的目标是一个物体只保留一个最优的框，于是我们就要用到非极大值抑制（Non-maximum Suppression）来抑制那些冗余的框，抑制的过程是一个迭代-遍历-消除的过程。 我们先将所有的框的得分排序，选中最高分及其对应的框。 然后遍历其余的框，如果和当前最高分框的IOU大于一定阈值，我们就将框删除。 从未处理的框中继续选出一个得分最高的，重复上述过程。 迁移学习实际上，深度学习在使用CNN的时候很少从头开始训练，通常都是使用预训练的模型（pretrained model）的参数作为初始化。引用cs231n的course note就是 In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest 通常的三种迁移策略如下： 把CNN当作特征提取，替换掉在ImageNet上训练好的CNN去掉最后的全连接层，冻结除了全连接层的其他层（训练过程不更新）。 Fine-tune。在训练最后全连接层的同时也更新其他层，比如高层的卷积层。 pretrained models 在RCNN中就使用了这种迁移学习。 文章思路R-CNN的贡献主要有三个： 速度大幅提升。传统的物体检测的方法很多是采用滑动窗口（Sliding Window）的方式来生成候选框（Region Proposals），计算量很大也非常耗时。R-CNN采用Selective Search的方法来生成候选框，简单来说selective search就是找出图片中那些最可能的候选框，大幅减少了候选框的个数。 全新的架构。首先生成可能的候选框，然后把这个区域送给CNN去做分类和bounding box的回归。这种two-stage的架构是后来许多工作的基础。 准确率大幅提升。一般来说，特征越强大，那么分类的效果就越好。所以ImageNet训练的高精确度的分类模型，在R-CNN这个方法中，就是“巨人的肩膀”。 网络结构RCNN的算法分为四个步骤： 对每一张图像采用selective search的方式生成1～2k的候选区域 对每一个候选区域（需要将每一个候选区域scale到相同的大小$227\times227$），使用CNN提取特征（请思考每一个候选区域的含义） 特征送入每一类的SVM分类器，判别是否属于该类（分类问题） 使用回归精细修正候选框的位置（回归问题） 上图是原论文中的流程图，cs231n的图能更加直观的看出RCNN的流程。 下面说一说训练过程和测试过程的一些细节 训练过程Supervised pre-training首先是有监督的预训练阶段，也就是在背景知识介绍的迁移学习的部分。将在ImageNet分类任务上预训练好的网络的参数直接作为RCNN中CNN部分的初始化参数。 Fine-tuning假设要检测的物体类别有N类，将预训练的CNN的最后一层替换成有N+1个输出的分类器（N+1代表N个类别加上1个background）。定义region proposals和ground truth的IOU（参加背景知识）$\geq 0.5$的视为positive，其余的视为negative。每个batch-size设为128，包括32个positive和96个negative。 Object category classifiers接下来就是正式的训练了。这个时候positive和negative的定义和fine-tune阶段有所不同，当$IOU\le 0.3$定义为负样本（作者实验得出）。 与fine-tune阶段的第二个不同是对每一个类都有一个二分类的SVM，N个类对应的就有N个SVM。 Bounding-box Regression目标检测问题的衡量标准是IOU，许多看似准确的检测结果，往往因为候选框不过准确导致IOU很小，所以需要一个位置精修的回归。 每一个候选框都可以用四个参数$x,y,w,h$来描述，其中$(x,y)$代表左上角坐标，$(w,h)$代表宽度和高度，通过一个线性回归器对这四个值进行回归，以此来修正Bounding Box 测试过程说完了训练过程，下面说说测试过程。 首先对于一张测试图片，我们通过selective search的方法生成2000个候选区域，每一个候选区域都送入CNN生成4096维的特征，送入SVM得到N个score。这样对于2000个候选区域，我们就得到了$2000\times N$的score matrix。 然后对每一个类别都采用非极大值抑制选出候选框，一次处理一个类别，共处理N次。 测试过程的速度大概是GPU上13s/image，CPU上53s/image（可以看到速度很慢，这对于要求实施检测的任务显然不过关）。作者认为CNN参数共享，得到的低维特征使得R-CNN非常高效。 总结 论文发表的2014年，DPM已经进入瓶颈期，即使使用复杂的特征和结构得到的提升也十分有限。本文将深度学习引入检测领域，一举将PASCAL VOC上的检测率从35.1%提升到53.7%。 R-CNN不管从速度还是精度上都比之前的工作有了很大的改进，这很大部分得益于CNN的引进。但是不得不说，R-CNN也有许多不足之处，尤其是速度，这也是后来许多改进工作的出发点： 多个特定的训练目标(ad hoc training objectives) Fine-tune的时候用softmax classifier(log loss) 训练的时候分类用的线形SVM(hinge loss) 训练的时候用的bounding-box regression(least squares) 训练过程很慢（84h），占用很多内存 测试过程也很慢，离实时检测的目标很远 接下来会介绍SPP-Net, Fast-RCNN, Faster-RCNN等在R-CNN基础上的改进工作，也会介绍一下one-stage的物体检测YOLO和YOLO9000。 参考文献 Rich feature hierarchies for Accurate Object Detection and Segmentation CS231n 基于R-CNN的物体检测 [目标检测]RCNN算法详解 NMS-非极大值抑制]]></content>
      <categories>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>deep-learning</tag>
        <tag>computer-vision</tag>
        <tag>object-detection</tag>
      </tags>
  </entry>
</search>
